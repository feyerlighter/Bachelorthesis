@article{andersonDockerSoftwareEngineering2015,
  title = {Docker [{{Software}} Engineering]},
  author = {Anderson, Charles},
  date = {2015-05},
  journaltitle = {IEEE Software},
  volume = {32},
  number = {3},
  pages = {102-c3},
  issn = {1937-4194},
  doi = {10.1109/MS.2015.62},
  url = {https://ieeexplore.ieee.org/document/7093032/figures#figures},
  urldate = {2024-10-03},
  abstract = {In episode 217 of Software Engineering Radio, host Charles Anderson talks with James Turnbull, a software developer and security specialist who's vice president of services at Docker. Lightweight Docker containers are rapidly becoming a tool for deploying microservice-based architectures.},
  eventtitle = {{{IEEE Software}}},
  keywords = {Docker,Docker containers,Interviews,James Turnbull,microservices,SE Radio,Software development,Software engineering,Software Engineering Radio,Virtual machining}
}

@article{krishnamoorthyEvolutionReadingComprehension2021,
  title = {Evolution of {{Reading Comprehension}} and {{Question Answering Systems}}},
  author = {Krishnamoorthy, Venkatesh},
  date = {2021-01-01},
  journaltitle = {Procedia Computer Science},
  shortjournal = {Procedia Computer Science},
  series = {Big {{Data}}, {{IoT}}, and {{AI}} for a {{Smarter Future}}},
  volume = {185},
  pages = {231--238},
  issn = {1877-0509},
  doi = {10.1016/j.procs.2021.05.024},
  url = {https://www.sciencedirect.com/science/article/pii/S1877050921011066},
  urldate = {2024-10-03},
  abstract = {Natural Language Processing (NLP) has witnessed considerable advances in textual understanding through statistical and rule-based techniques, which have now yielded to developments in the field of neural networks and deep learning. The paper surveys research relevant to the topic of Reading Comprehension and Question Answering (QA) implementations. The initial focus of the paper is on Attention and Transformer models. A brief description of the architectures is presented highlighting the essence of the ‘Attention is all you Need’ paper wherein the authors of Bidirectional Encoding Transformer (BERT) have elucidated the significant departure from the recurrence concept of Recurrent Neural Networks (RNN). Subsequently the trends in Open Domain Question Answering (ODQA) which mark the progression from the passage- based question answering is presented. Of particular interest is Haystack which is an end-to-end open-source framework for Question Answering \& Neural search. This field seems a promising avenue for a more intelligent form of ‘search’. In a nutshell, the paper weaves through RNNs, Long Short-Term Memory (LSTM), and the currently trending Attention based Transformer models in NLP. Finally, we dwell on more contemporary pieces of research such as ODQA, Multi-Hop QA, evaluation using Adversarial Networks.},
  keywords = {Attention,BERT,ELMo,HayStack,Knowledge Graph,LSTM,Multi-Hop,RNN,SQUaD,Transfer Learning,Transformer}
}

@article{syedQuestionAnsweringChatbot2021,
  title = {Question {{Answering Chatbot}} for {{Troubleshooting Queries}} Based on {{Transfer Learning}}},
  author = {Syed, Zeeshan Haque and Trabelsi, Asma and Helbert, Emmanuel and Bailleau, Vincent and Muths, Christian},
  date = {2021},
  journaltitle = {Procedia Computer Science},
  shortjournal = {Procedia Computer Science},
  volume = {192},
  pages = {941--950},
  issn = {18770509},
  doi = {10.1016/j.procs.2021.08.097},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050921015854},
  urldate = {2024-10-03},
  abstract = {Open-Domain Question Answering (ODQA) is a technique for finding an answer to a given query from a large set of documents. In this paper, we present an experimentation study to compare ODQA candidate solutions in the context of troubleshooting documents. We mainly focus on a well known open-source framework which is called Haystack. This framework comprises two key components which are the Retriever and the Reader. The Haystack Framework comes with several Retriever-Reader combinations and the choice of the best one is still unanswered till now. In this paper, we conduct an experimentation study to compare different Retriever-Reader combinations. Our aim is to come up with the best combination of components in regard to the speed and the processing power within the context of troubleshooting queries.},
  langid = {english},
  file = {/Users/A200017936/Zotero/storage/425ZNZ74/Syed et al. - 2021 - Question Answering Chatbot for Troubleshooting Queries based on Transfer Learning.pdf}
}
